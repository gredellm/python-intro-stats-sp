{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for the notebook\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Confidence Intervals in Python\n",
    "\n",
    "Significance testing can tell us whether or not sample data is significant evidence against the null hypothesis, but it fails to provide us with an estimate for the true value of the parameter of interest. For this, a statistician will build a *confidence interval* to determine a range of possible values for the parameter at some specified *confidence level.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Heads on fair coin: 165\n",
      "Number of Heads on biased coin: 192\n",
      "\n",
      "\n",
      "Proportion of Heads on fair coin: 0.55\n",
      "Proportion of Heads on biased coin: 0.64\n"
     ]
    }
   ],
   "source": [
    "# Specify sample size and number of samples to be generated\n",
    "\n",
    "sample_size = 300\n",
    "\n",
    "# Generate the samples and total the success counts from each sample, then print results\n",
    "\n",
    "fair_tosses_count = np.random.binomial(n = sample_size, p = .5)\n",
    "biased_tosses_count = np.random.binomial(n = sample_size, p = .6)\n",
    "\n",
    "print(\"Number of Heads on fair coin:\", fair_tosses_count)\n",
    "print(\"Number of Heads on biased coin:\", biased_tosses_count)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# Convert the counts to proportions for the intervals, then print\n",
    "\n",
    "p_hat_fair = fair_tosses_count / sample_size \n",
    "p_hat_biased = biased_tosses_count / sample_size\n",
    "\n",
    "print(\"Proportion of Heads on fair coin:\", p_hat_fair)\n",
    "print(\"Proportion of Heads on biased coin:\", p_hat_biased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our estimates for the parameter *p*, the long-run probability that each coin comes up heads, we can generate confidence intervals to get a better idea of how sure we are of our estimates. To do this, we'll need two pieces of information. \n",
    "\n",
    "First, we'll need a *critical value.* The critical value comes from the distribution we're basing our inference on and determines how confident we'd like to be in our interval. In this scenario, we'll be using the normal distribution to approximate the intervals at the 95% confidence level. Many tables of critical values for the normal distribution are available online and in statistics textbooks, which confirm that the critical value we'll want to use is *z* * = 1.96. \n",
    "\n",
    "Second, we'll need to calculate the *standard error* for each interval. The standard error is a measure of variability based on our sample probabilities of success and the number of trials we observed.\n",
    "\n",
    "The product of the critical value and the standard error gives us the *margin of error* for the confidence interval.\n",
    "\n",
    "Let's start with the fair coin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for the probability that Coin 1 (our fair coin) lands on heads: ( 0.494 ,  0.606 )\n"
     ]
    }
   ],
   "source": [
    "# For this example, we'll specify the critical value beforehand:\n",
    "z_star = 1.96\n",
    "\n",
    "# Calculate standard error\n",
    "se_fair = np.sqrt((p_hat_fair * (1 - p_hat_fair)) / sample_size)\n",
    "\n",
    "# Then calculate margin of error\n",
    "moe_fair = z_star * se_fair\n",
    "\n",
    "# Find the lower and upper bounds for the confidence interval\n",
    "lb_fair = round((p_hat_fair - moe_fair), 3)\n",
    "ub_fair = round((p_hat_fair + moe_fair), 3)\n",
    "\n",
    "print(\"95% confidence interval for the probability that Coin 1 (our fair coin) lands on heads: (\", lb_fair, \", \", ub_fair, \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've determined now that we are 95% confident that the long-run probability that the fair coin lands on heads is between 0.453 and 0.567.\n",
    "\n",
    "Now, for the biased coin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for the probability that Coin 2 (our biased coin) lands on heads: ( 0.586 ,  0.694 )\n"
     ]
    }
   ],
   "source": [
    "# Calculate standard error\n",
    "se_biased = np.sqrt((p_hat_biased * (1 - p_hat_biased)) / sample_size)\n",
    "\n",
    "# Then find margin of error \n",
    "moe_biased = z_star * se_biased\n",
    "\n",
    "# Find the lower and upper bounds for the interval\n",
    "lb_biased = round((p_hat_biased - moe_biased), 3)\n",
    "ub_biased = round((p_hat_biased + moe_biased), 3)\n",
    "\n",
    "print(\"95% confidence interval for the probability that Coin 2 (our biased coin) lands on heads: (\", \n",
    "      lb_biased, \", \", ub_biased, \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are 95% confident that the long-run probability that the biased coin lands on heads is between 0.524 and 0.636.\n",
    "\n",
    "Above, we wrote in the critical value as part of our code, which we can do if we already know the value ahead of time. Alternatively, if we are crafty, we could have Python find the critical value for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python says that z* is about 1.96\n"
     ]
    }
   ],
   "source": [
    "# Import commands for the normal distribution from the scipy.stats library\n",
    "from scipy.stats import norm\n",
    "\n",
    "# We are concerned with the  middle 95%  of the distribution, so we look for the critical value such that the \n",
    "# weight we are not concerned with is evenly distributed between the tails:\n",
    "prob = 0.975\n",
    "python_z_star = round(norm.ppf(prob), 3)\n",
    "\n",
    "print(\"Python says that z* is about\", python_z_star)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
